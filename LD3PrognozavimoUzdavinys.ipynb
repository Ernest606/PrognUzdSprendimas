{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5c-Yre2uK_n",
        "outputId": "7a984e6b-af98-46b8-bc12-305f988ed9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-61ec3b8fdbdf>:5: DtypeWarning: Columns (1,2,3,7,8,9,11,12,13,14,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    item_id          status created_at  \\\n",
            "0  211131.0        complete   7/1/2016   \n",
            "1  211133.0        canceled   7/1/2016   \n",
            "2  211134.0        canceled   7/1/2016   \n",
            "3  211135.0        complete   7/1/2016   \n",
            "4  211136.0  order_refunded   7/1/2016   \n",
            "\n",
            "                                                 sku   price  qty_ordered  \\\n",
            "0                                  kreations_YI 06-L  1950.0          1.0   \n",
            "1  kcc_Buy 2 Frey Air Freshener & Get 1 Kasual Bo...   240.0          1.0   \n",
            "2                                 Ego_UP0017-999-MR0  2450.0          1.0   \n",
            "3                                     kcc_krone deal   360.0          1.0   \n",
            "4                                        BK7010400AG   555.0          2.0   \n",
            "\n",
            "   grand_total increment_id    category_name_1 sales_commission_code  ...  \\\n",
            "0       1950.0    100147443    Women's Fashion                    \\N  ...   \n",
            "1        240.0    100147444  Beauty & Grooming                    \\N  ...   \n",
            "2       2450.0    100147445    Women's Fashion                    \\N  ...   \n",
            "3         60.0    100147446  Beauty & Grooming           R-FSD-52352  ...   \n",
            "4       1110.0    100147447            Soghaat                    \\N  ...   \n",
            "\n",
            "   Month Customer Since     M-Y    FY Customer ID  Unnamed: 21  Unnamed: 22  \\\n",
            "0    7.0         2016-7  7-2016  FY17         1.0          NaN          NaN   \n",
            "1    7.0         2016-7  7-2016  FY17         2.0          NaN          NaN   \n",
            "2    7.0         2016-7  7-2016  FY17         3.0          NaN          NaN   \n",
            "3    7.0         2016-7  7-2016  FY17         4.0          NaN          NaN   \n",
            "4    7.0         2016-7  7-2016  FY17         5.0          NaN          NaN   \n",
            "\n",
            "  Unnamed: 23 Unnamed: 24 Unnamed: 25  \n",
            "0         NaN         NaN         NaN  \n",
            "1         NaN         NaN         NaN  \n",
            "2         NaN         NaN         NaN  \n",
            "3         NaN         NaN         NaN  \n",
            "4         NaN         NaN         NaN  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "____________________________________________________\n",
            "           status                                                sku   price  \\\n",
            "0        complete                                  kreations_YI 06-L  1950.0   \n",
            "1        canceled  kcc_Buy 2 Frey Air Freshener & Get 1 Kasual Bo...   240.0   \n",
            "2        canceled                                 Ego_UP0017-999-MR0  2450.0   \n",
            "3        complete                                     kcc_krone deal   360.0   \n",
            "4  order_refunded                                        BK7010400AG   555.0   \n",
            "\n",
            "   qty_ordered  grand_total    category_name_1  Customer ID  \n",
            "0          1.0       1950.0    Women's Fashion          1.0  \n",
            "1          1.0        240.0  Beauty & Grooming          2.0  \n",
            "2          1.0       2450.0    Women's Fashion          3.0  \n",
            "3          1.0         60.0  Beauty & Grooming          4.0  \n",
            "4          2.0       1110.0            Soghaat          5.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'Pakistan Largest Ecommerce Dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "# List of columns to drop\n",
        "columns_to_drop = ['item_id', ' MV ', 'created_at', 'increment_id', 'sales_commission_code', 'discount_amount', 'payment_method', 'Working Date', 'BI Status', 'Year', 'Month', 'Customer Since', 'M-Y', 'FY', \"Unnamed: 21\", \"Unnamed: 22\", \"Unnamed: 23\", \"Unnamed: 24\", \"Unnamed: 25\"]\n",
        "data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "print(\"____________________________________________________\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Duomenu analize\n",
        "print(data.isnull().sum())\n",
        "print(\"__________________________\")\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(\"__________________________\")\n",
        "\n",
        "num_records = data.shape[0]\n",
        "print(f\"Number of records in the DataFrame: {num_records}\")\n",
        "\n",
        "\n",
        "data['Customer ID'] = data['Customer ID'].astype('int32')\n",
        "data['price'] = data['price'].astype('float32')\n",
        "data['qty_ordered'] = data['qty_ordered'].astype('float32')\n",
        "data['grand_total'] = data['grand_total'].astype('float32')\n",
        "data['status'] = data['status'].astype('category')\n",
        "data['sku'] = data['sku'].astype('object')\n",
        "data['price'] = data['price'].astype('float32')\n",
        "data['category_name_1'] = data['category_name_1'].astype('category')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sCcfT7s_VPj",
        "outputId": "bd5f8eae-3180-4060-8055-394aeb1d624e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "status             464066\n",
            "sku                464071\n",
            "price              464051\n",
            "qty_ordered        464051\n",
            "grand_total        464051\n",
            "category_name_1    464215\n",
            "Customer ID        464062\n",
            "dtype: int64\n",
            "__________________________\n",
            "status             0\n",
            "sku                0\n",
            "price              0\n",
            "qty_ordered        0\n",
            "grand_total        0\n",
            "category_name_1    0\n",
            "Customer ID        0\n",
            "dtype: int64\n",
            "__________________________\n",
            "Number of records in the DataFrame: 584314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of orders per \"Customer ID\"\n",
        "order_counts = data['Customer ID'].value_counts()\n",
        "print(\"Number of orders per Customer ID:\")\n",
        "print(order_counts)\n",
        "\n",
        "# Count the number of orders per \"sku (Product name)\"\n",
        "sku_counts = data['sku'].value_counts()\n",
        "print(\"Number of orders per sku:\")\n",
        "print(sku_counts)\n",
        "\n",
        "# Count the number of orders per \"status\"\n",
        "status_counts = data['status'].value_counts()\n",
        "print(\"Number of orders per status:\")\n",
        "print(status_counts)\n",
        "\n",
        "cleaned_data_path = 'cleaned_ecommerce_data.csv'\n",
        "data.to_csv(cleaned_data_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmFh_TmqHDQj",
        "outputId": "4cdf13f1-61dd-496c-faad-8f49c06f8aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of orders per Customer ID:\n",
            "Customer ID\n",
            "85775     2524\n",
            "163       2349\n",
            "35        1877\n",
            "33        1397\n",
            "31025     1369\n",
            "          ... \n",
            "52111        1\n",
            "52114        1\n",
            "52116        1\n",
            "52118        1\n",
            "115326       1\n",
            "Name: count, Length: 115304, dtype: int64\n",
            "Number of orders per sku:\n",
            "sku\n",
            "MATSAM59DB75ADB2F80              3775\n",
            "Al Muhafiz Sohan Halwa Almond    2258\n",
            "emart_00-7                       2027\n",
            "kcc_krone deal                   1894\n",
            "infinix_Zero 4-Grey              1793\n",
            "                                 ... \n",
            "WOFBAT5A0144DB102B3-37              1\n",
            "Essential_003-M                     1\n",
            "BAGRAS59AE3485778F2                 1\n",
            "BAGULR59E84898A97E1                 1\n",
            "WOFSCE5AE00357AECDE                 1\n",
            "Name: count, Length: 84869, dtype: int64\n",
            "Number of orders per sku:\n",
            "status\n",
            "complete          233684\n",
            "canceled          201127\n",
            "received           77284\n",
            "order_refunded     59498\n",
            "refund              8020\n",
            "cod                 2854\n",
            "paid                1159\n",
            "closed               494\n",
            "payment_review        57\n",
            "pending               48\n",
            "processing            33\n",
            "holded                31\n",
            "fraud                 10\n",
            "pending_paypal         7\n",
            "\\N                     4\n",
            "exchange               4\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define data types\n",
        "dtypes = {\n",
        "    'status': 'category',\n",
        "    'sku': 'object',\n",
        "    'price': 'float32',\n",
        "    'qty_ordered': 'float32',\n",
        "    'grand_total': 'float32',\n",
        "    'category_name_1': 'category',\n",
        "    'Customer ID': 'int32'\n",
        "}\n",
        "\n",
        "# Load your dataset in chunks\n",
        "file_path = 'cleaned_ecommerce_data.csv'\n",
        "chunk_size = 10000\n",
        "\n",
        "# Initialize encoders\n",
        "encoder_sku = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
        "encoder_category = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
        "\n",
        "all_labels = set()\n",
        "\n",
        "# Process data in chunks and collect all unique labels\n",
        "for chunk in pd.read_csv(file_path, chunksize=chunk_size, dtype=dtypes):\n",
        "    # Remove rows with missing SKUs or Customer IDs\n",
        "    chunk = chunk.dropna(subset=['sku', 'Customer ID'])\n",
        "\n",
        "    # Transform 'status' to a binary indicator\n",
        "    chunk['status'] = chunk['status'].apply(lambda x: 1 if x in ['complete', 'received'] else 0)\n",
        "\n",
        "    # Filter only completed purchases for training the next SKU model\n",
        "    chunk = chunk[chunk['status'] == 1].copy()\n",
        "\n",
        "    # Create target variable (next SKU to buy)\n",
        "    chunk['next_sku'] = chunk.groupby('Customer ID')['sku'].shift(-1)\n",
        "\n",
        "    # Drop rows with missing target variable\n",
        "    chunk = chunk.dropna(subset=['next_sku'])\n",
        "\n",
        "    # Collect all unique labels\n",
        "    all_labels.update(chunk['next_sku'].unique())\n",
        "\n",
        "    # Fit encoders on the current chunk\n",
        "    encoder_sku.fit(chunk[['sku']])\n",
        "    encoder_category.fit(chunk[['category_name_1']])\n",
        "\n",
        "# Save the fitted encoders\n",
        "joblib.dump(encoder_sku, 'encoder_sku.pkl')\n",
        "joblib.dump(encoder_category, 'encoder_category.pkl')\n",
        "\n",
        "# Save all collected labels\n",
        "joblib.dump(list(all_labels), 'all_labels.pkl')\n",
        "\n",
        "# Incremental Model Training\n",
        "# Load the processed data in chunks again\n",
        "data_iterator = pd.read_csv(file_path, chunksize=chunk_size, dtype=dtypes)\n",
        "\n",
        "# Initialize the model\n",
        "model = SGDClassifier(random_state=42)\n",
        "\n",
        "# Initialize the label encoder with all labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(list(all_labels))\n",
        "\n",
        "# Perform incremental training with a progress bar\n",
        "for chunk in tqdm(data_iterator, desc=\"Training Progress\"):\n",
        "    # Remove rows with missing SKUs or Customer IDs\n",
        "    chunk = chunk.dropna(subset=['sku', 'Customer ID'])\n",
        "\n",
        "    # Transform 'status' to a binary indicator\n",
        "    chunk['status'] = chunk['status'].apply(lambda x: 1 if x in ['complete', 'received'] else 0)\n",
        "\n",
        "    # Filter only completed purchases for training the next SKU model\n",
        "    chunk = chunk[chunk['status'] == 1].copy()\n",
        "\n",
        "    # Create target variable (next SKU to buy)\n",
        "    chunk['next_sku'] = chunk.groupby('Customer ID')['sku'].shift(-1)\n",
        "\n",
        "    # Drop rows with missing target variable\n",
        "    chunk = chunk.dropna(subset=['next_sku'])\n",
        "\n",
        "    # One-hot encode the current chunk\n",
        "    encoded_sku = encoder_sku.transform(chunk[['sku']])\n",
        "    encoded_category = encoder_category.transform(chunk[['category_name_1']])\n",
        "\n",
        "    # Combine the original data with the encoded features\n",
        "    chunk_encoded = pd.concat([chunk.reset_index(drop=True),\n",
        "                               pd.DataFrame(encoded_sku.toarray(), columns=encoder_sku.get_feature_names_out(['sku'])),\n",
        "                               pd.DataFrame(encoded_category.toarray(), columns=encoder_category.get_feature_names_out(['category_name_1']))], axis=1)\n",
        "\n",
        "    # Drop original 'sku' and 'category_name_1' columns and 'status'\n",
        "    chunk_encoded = chunk_encoded.drop(columns=['sku', 'category_name_1', 'status'])\n",
        "\n",
        "    # Define features and target\n",
        "    X_chunk = chunk_encoded.drop(columns=['next_sku'])\n",
        "    y_chunk = chunk_encoded['next_sku']\n",
        "\n",
        "    # Transform the target variable\n",
        "    y_chunk_encoded = label_encoder.transform(y_chunk)\n",
        "\n",
        "    # Perform partial fit\n",
        "    model.partial_fit(X_chunk, y_chunk_encoded, classes=label_encoder.transform(label_encoder.classes_))\n",
        "\n",
        "# Save the trained model and label encoder\n",
        "joblib.dump(model, 'sku_prediction_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIafrrmYOAxt",
        "outputId": "9bb91b24-a85a-4f10-fd5a-148c0ca06a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 59it [2:18:39, 141.01s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the fitted encoders and model\n",
        "encoder_sku = joblib.load('encoder_sku.pkl')\n",
        "encoder_category = joblib.load('encoder_category.pkl')\n",
        "model = joblib.load('sku_prediction_model.pkl')\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "\n",
        "# Define data types\n",
        "dtypes = {\n",
        "    'status': 'category',\n",
        "    'sku': 'object',\n",
        "    'price': 'float32',\n",
        "    'qty_ordered': 'float32',\n",
        "    'grand_total': 'float32',\n",
        "    'category_name_1': 'category',\n",
        "    'Customer ID': 'int32'  # Or 'object' if Customer ID includes non-numeric values\n",
        "}\n",
        "\n",
        "# Load the full dataset with specified data types\n",
        "file_path = 'cleaned_ecommerce_data.csv'  # Update this path to your dataset location\n",
        "data = pd.read_csv(file_path, dtype=dtypes)\n",
        "\n",
        "# Remove rows with missing SKUs or Customer IDs\n",
        "data = data.dropna(subset=['sku', 'Customer ID'])\n",
        "\n",
        "# Transform 'status' to a binary indicator\n",
        "data['status'] = data['status'].apply(lambda x: 1 if x in ['complete', 'received'] else 0)\n",
        "\n",
        "# Function to get the next SKU prediction for a specific user\n",
        "def user_next_sku_prediction(user_id):\n",
        "    # Filter data for the specific user\n",
        "    user_data = data[data['Customer ID'] == user_id]\n",
        "\n",
        "    if user_data.empty:\n",
        "        print(\"User ID not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Display what the user has already bought\n",
        "    print(f\"Purchase history for user {user_id}:\")\n",
        "    print(user_data[['sku', 'category_name_1', 'qty_ordered', 'price', 'grand_total']])\n",
        "\n",
        "    # Prepare the data for prediction\n",
        "    encoded_sku = encoder_sku.transform(user_data[['sku']])\n",
        "    encoded_category = encoder_category.transform(user_data[['category_name_1']])\n",
        "\n",
        "    # Combine encoded features\n",
        "    encoded_features = hstack([encoded_sku, encoded_category])\n",
        "\n",
        "    # Aggregate encoded features\n",
        "    encoded_features_agg = encoded_features.sum(axis=0)\n",
        "\n",
        "    # Aggregate user data\n",
        "    user_agg_data = user_data.groupby('Customer ID').agg({\n",
        "        'price': 'sum',\n",
        "        'qty_ordered': 'sum',\n",
        "        'grand_total': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Combine encoded features with user aggregated data\n",
        "    agg_values = user_agg_data.drop(columns=['Customer ID']).values\n",
        "    agg_values_csr = csr_matrix(agg_values)\n",
        "    final_features = hstack([encoded_features_agg, agg_values_csr])\n",
        "\n",
        "    # Convert to CSR format for subscriptable operations\n",
        "    final_features = final_features.tocsr()\n",
        "\n",
        "    # Ensure the final feature dimensions match\n",
        "    num_features_model = model.n_features_in_\n",
        "    if final_features.shape[1] != num_features_model:\n",
        "        if final_features.shape[1] < num_features_model:\n",
        "            # Add zero columns to match dimensions\n",
        "            zero_padding = csr_matrix((final_features.shape[0], num_features_model - final_features.shape[1]))\n",
        "            final_features = hstack([final_features, zero_padding])\n",
        "        elif final_features.shape[1] > num_features_model:\n",
        "            # Truncate columns to match dimensions\n",
        "            final_features = final_features[:, :num_features_model]\n",
        "\n",
        "    # Predict the next SKU\n",
        "    next_sku_pred = model.predict(final_features)\n",
        "    next_sku = label_encoder.inverse_transform(next_sku_pred)\n",
        "\n",
        "    print(f\"\\nPredicted next item for user {user_id}: {next_sku[0]}\")\n",
        "\n",
        "# Example usage\n",
        "user_id = 35  # Replace with an actual user ID from your dataset\n",
        "user_next_sku_prediction(user_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMs8VV11dip_",
        "outputId": "ce2754c7-9644-407b-dedf-e1109063b251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purchase history for user 35:\n",
            "                        sku    category_name_1  qty_ordered        price  \\\n",
            "59            itter_AB 1214  Beauty & Grooming          1.0   300.000000   \n",
            "67            ajmery_F9-981      Men's Fashion          1.0   999.000000   \n",
            "70           kcc_krone deal  Beauty & Grooming          1.0   360.000000   \n",
            "71      RS_Habshi Halwa Tin            Soghaat          1.0   280.000000   \n",
            "262              Haier M106  Mobiles & Tablets          1.0  2490.000000   \n",
            "...                     ...                ...          ...          ...   \n",
            "121732          stinnos_945        Kids & Baby          1.0   940.000000   \n",
            "122442      Essential_006-L      Men's Fashion          1.0   425.000000   \n",
            "122444      Essential_005-L      Men's Fashion          1.0   425.000000   \n",
            "122446     Aybeez_ABZ-277-L      Men's Fashion          1.0   439.600006   \n",
            "122507      Essential_005-M      Men's Fashion          1.0   425.000000   \n",
            "\n",
            "        grand_total  \n",
            "59       300.000000  \n",
            "67       999.000000  \n",
            "70       360.000000  \n",
            "71       280.000000  \n",
            "262     2490.000000  \n",
            "...             ...  \n",
            "121732   940.000000  \n",
            "122442   425.000000  \n",
            "122444   425.000000  \n",
            "122446   439.600006  \n",
            "122507   425.000000  \n",
            "\n",
            "[1877 rows x 5 columns]\n",
            "\n",
            "Predicted next item for user 35: VIT5ABCCF7FDF973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}